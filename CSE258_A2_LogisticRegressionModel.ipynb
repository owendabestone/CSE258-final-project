{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(\"renttherunway_final_data.json.gz\")\n",
    "dataset1 = []\n",
    "for l in f:\n",
    "    dataset1.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit': 'fit',\n",
       " 'user_id': '273551',\n",
       " 'bust size': '34b',\n",
       " 'item_id': '153475',\n",
       " 'weight': '132lbs',\n",
       " 'rating': '10',\n",
       " 'rented for': 'other',\n",
       " 'review_text': 'I rented this dress for a photo shoot. The theme was \"Hollywood Glam and Big Beautiful Hats\". The dress was very comfortable and easy to move around in. It is definitely on my list to rent again for another formal event. ',\n",
       " 'body type': 'straight & narrow',\n",
       " 'review_summary': 'I felt so glamourous!!!',\n",
       " 'category': 'gown',\n",
       " 'height': '5\\' 6\"',\n",
       " 'size': 12,\n",
       " 'age': '36',\n",
       " 'review_date': 'June 18, 2013'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192544"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: Model does not use any user info or temporal characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset1[:180000]\n",
    "test = dataset1[180000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    incorrect = np.sum(np.logical_xor(predictions, y))\n",
    "    total = len(y)\n",
    "    accuracy = (total - incorrect)/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorization_accuracy(prediction, y):\n",
    "    ls = [prediction[i]==y[i] for i in range(len(y))]\n",
    "    correct = np.sum(ls)\n",
    "    total = len(y)\n",
    "    cat_accuracy = correct / total\n",
    "    return cat_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful data structures\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in train:\n",
    "    u = d['user_id']\n",
    "    i = d['item_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(u,i):\n",
    "    fs = []\n",
    "    fits = [d['fit'] for d in reviewsPerItem[i]]\n",
    "    fs.append(len(fits))\n",
    "    fs.append(fits.count('fit')/(len(fits)+0.1))\n",
    "    fs.append(fits.count('small')/(len(fits)+0.1))\n",
    "    fs.append(fits.count('large')/(len(fits)+0.1))\n",
    "    return [1] + fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [features(d['user_id'],d['item_id']) for d in train]\n",
    "X_test = [features(d['user_id'],d['item_id']) for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_fit = [d['fit']==\"fit\" for d in train]\n",
    "y_test_fit = [d['fit']==\"fit\" for d in test]\n",
    "\n",
    "y_train_small = [d['fit']==\"small\" for d in train]\n",
    "y_test_small = [d['fit']==\"small\" for d in test]\n",
    "\n",
    "y_train_large = [d['fit']==\"large\" for d in train]\n",
    "y_test_large = [d['fit']==\"large\" for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7502391581632653\n"
     ]
    }
   ],
   "source": [
    "mod_fit = linear_model.LogisticRegression(fit_intercept=False, max_iter=200, C=1)\n",
    "mod_fit.fit(X_train,y_train_fit)\n",
    "y_test_pred = mod_fit.predict(X_test)\n",
    "print(accuracy(y_test_pred,y_test_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696588010204082\n"
     ]
    }
   ],
   "source": [
    "mod_small = linear_model.LogisticRegression(fit_intercept=False, max_iter=200, C=1)\n",
    "mod_small.fit(X_train,y_train_small)\n",
    "y_test_pred = mod_small.predict(X_test)\n",
    "print(accuracy(y_test_pred,y_test_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8783482142857143\n"
     ]
    }
   ],
   "source": [
    "mod_large = linear_model.LogisticRegression(fit_intercept=False, max_iter=200, C=1)\n",
    "mod_large.fit(X_train,y_train_large)\n",
    "y_test_pred = mod_large.predict(X_test)\n",
    "print(accuracy(y_test_pred,y_test_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prediction(X):\n",
    "    fit_percent = mod_fit.predict_proba(X)\n",
    "    small_percent = mod_small.predict_proba(X)\n",
    "    large_percent = mod_large.predict_proba(X)\n",
    "    \n",
    "    percents = list(zip(fit_percent[:,1],small_percent[:,1],large_percent[:,1]))\n",
    "    preds = []\n",
    "    for i in range(len(X)):\n",
    "        f,s,l = percents[i]\n",
    "        #print(f,s,l)\n",
    "        if l > s and l > f:\n",
    "            preds.append('large')\n",
    "        elif s > f and s > l:\n",
    "            preds.append('small')\n",
    "        else:\n",
    "            preds.append('fit')\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorization Accuracy of Model:  0.75\n"
     ]
    }
   ],
   "source": [
    "y = [d['fit'] for d in test]\n",
    "preds = class_prediction(X_test)\n",
    "print(\"Categorization Accuracy of Model: \", categorization_accuracy(preds, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
